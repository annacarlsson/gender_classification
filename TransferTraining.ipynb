{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-30T16:05:23.185020Z",
     "start_time": "2019-05-30T16:05:22.356321Z"
    },
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Nadam\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard, LearningRateScheduler\n",
    "from models.models import *\n",
    "import tensorflow as tf\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-30T16:05:23.188187Z",
     "start_time": "2019-05-30T16:05:23.186340Z"
    }
   },
   "outputs": [],
   "source": [
    "# Number of searches performed\n",
    "hyperparameter_iterations = 5\n",
    "# epochs*(1frozen + 2unfrozen)\n",
    "epochs = 15\n",
    "# Batch size too small, bad approximation of the global loss.\n",
    "# Too large, gets stuck in minima.\n",
    "batch_size = 16\n",
    "\n",
    "# Default input size for many architectures\n",
    "image_size = (224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-30T16:05:23.410731Z",
     "start_time": "2019-05-30T16:05:23.189522Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 790 images belonging to 2 classes.\n",
      "Found 396 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Dataset folder, expects three subdirectories:\n",
    "# validation, train, test\n",
    "dataset = Path('Adience_dataset/')\n",
    "val_test_gen = ImageDataGenerator(rescale=1./255)\n",
    "validation = val_test_gen.flow_from_directory(dataset / 'validation',\n",
    "                                              target_size=image_size,\n",
    "                                              batch_size=batch_size,\n",
    "                                              class_mode='categorical', shuffle=False)\n",
    "\n",
    "test = val_test_gen.flow_from_directory(dataset / 'test',\n",
    "                                        target_size=image_size,\n",
    "                                        batch_size=1,\n",
    "                                        class_mode='categorical', shuffle=False)\n",
    "validation_steps = int(np.ceil(validation.n/batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-30T16:05:24.424972Z",
     "start_time": "2019-05-30T16:05:23.414681Z"
    }
   },
   "outputs": [],
   "source": [
    "# Random search\n",
    "# Architecture\n",
    "#architecture = MobileNetGenderFConnected(image_size, alpha=0.75, filter_factor=398, l2_factor=6.45E-04)\n",
    "#architecture = MobileNetGender(image_size, alpha, filter_factor, l2_factor)\n",
    "#architecture = InceptionGenderV3(image_size, filter_factor=447, l2_factor=7.50E-04)\n",
    "architecture = VGGGender(image_size, filter_factor=585, l2_factor=1.05E-04)\n",
    "\n",
    "train_gen = ImageDataGenerator(rescale=1./255,\n",
    "                               horizontal_flip=True,\n",
    "                               shear_range=3.22E+02,\n",
    "                               rotation_range=155)\n",
    "\n",
    "# Load weights\n",
    "model = architecture.model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-30T16:05:24.621779Z",
     "start_time": "2019-05-30T16:05:24.426097Z"
    }
   },
   "outputs": [],
   "source": [
    "#model.load_weights('Saved models/InceptionV3_447_l2_7.50E-04_rotation_155_shear_3.22E+02.hdf5')\n",
    "model.load_weights('Saved models/VGG16_585_l2_1.05E-04_rotation_136_shear_1.89E+02.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-30T18:03:59.406629Z",
     "start_time": "2019-05-30T16:05:24.622931Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6700 images belonging to 2 classes.\n",
      "Epoch 1/15\n",
      "419/419 [==============================] - 134s 319ms/step - loss: 1.4687 - acc: 0.5475 - val_loss: 0.8389 - val_acc: 0.7430\n",
      "Epoch 2/15\n",
      "419/419 [==============================] - 127s 303ms/step - loss: 1.4867 - acc: 0.5357 - val_loss: 0.8305 - val_acc: 0.7456\n",
      "Epoch 3/15\n",
      "419/419 [==============================] - 127s 303ms/step - loss: 1.4659 - acc: 0.5429 - val_loss: 0.8182 - val_acc: 0.7456\n",
      "Epoch 4/15\n",
      "419/419 [==============================] - 128s 306ms/step - loss: 1.4526 - acc: 0.5402 - val_loss: 0.7952 - val_acc: 0.7494\n",
      "Epoch 5/15\n",
      "419/419 [==============================] - 127s 304ms/step - loss: 1.4097 - acc: 0.5524 - val_loss: 0.7785 - val_acc: 0.7570\n",
      "Epoch 6/15\n",
      "419/419 [==============================] - 128s 305ms/step - loss: 1.3781 - acc: 0.5591 - val_loss: 0.7745 - val_acc: 0.7557\n",
      "Epoch 7/15\n",
      "419/419 [==============================] - 127s 303ms/step - loss: 1.3879 - acc: 0.5471 - val_loss: 0.7884 - val_acc: 0.7532\n",
      "Epoch 8/15\n",
      "419/419 [==============================] - 127s 303ms/step - loss: 1.3480 - acc: 0.5573 - val_loss: 0.7747 - val_acc: 0.7608\n",
      "Epoch 9/15\n",
      "419/419 [==============================] - 127s 304ms/step - loss: 1.3431 - acc: 0.5523 - val_loss: 0.7670 - val_acc: 0.7633\n",
      "Epoch 10/15\n",
      "419/419 [==============================] - 128s 306ms/step - loss: 1.3424 - acc: 0.5484 - val_loss: 0.7390 - val_acc: 0.7709\n",
      "Epoch 11/15\n",
      "419/419 [==============================] - 128s 305ms/step - loss: 1.3116 - acc: 0.5586 - val_loss: 0.7454 - val_acc: 0.7747\n",
      "Epoch 12/15\n",
      "419/419 [==============================] - 128s 305ms/step - loss: 1.2858 - acc: 0.5627 - val_loss: 0.7387 - val_acc: 0.7734\n",
      "Epoch 13/15\n",
      "419/419 [==============================] - 128s 305ms/step - loss: 1.2819 - acc: 0.5561 - val_loss: 0.7274 - val_acc: 0.7785\n",
      "Epoch 14/15\n",
      "419/419 [==============================] - 128s 305ms/step - loss: 1.2709 - acc: 0.5635 - val_loss: 0.7193 - val_acc: 0.7759\n",
      "Epoch 15/15\n",
      "419/419 [==============================] - 128s 306ms/step - loss: 1.2456 - acc: 0.5650 - val_loss: 0.7186 - val_acc: 0.7785\n",
      "Epoch 1/40\n",
      "419/419 [==============================] - 131s 313ms/step - loss: 1.0296 - acc: 0.6131 - val_loss: 0.6008 - val_acc: 0.7899\n",
      "Epoch 2/40\n",
      "419/419 [==============================] - 129s 307ms/step - loss: 0.8473 - acc: 0.6635 - val_loss: 0.5498 - val_acc: 0.8139\n",
      "Epoch 3/40\n",
      "419/419 [==============================] - 129s 307ms/step - loss: 0.7859 - acc: 0.6810 - val_loss: 0.5275 - val_acc: 0.8228\n",
      "Epoch 4/40\n",
      "419/419 [==============================] - 128s 306ms/step - loss: 0.7239 - acc: 0.7006 - val_loss: 0.5333 - val_acc: 0.8165\n",
      "Epoch 5/40\n",
      "419/419 [==============================] - 129s 307ms/step - loss: 0.6891 - acc: 0.7140 - val_loss: 0.4186 - val_acc: 0.8430\n",
      "Epoch 6/40\n",
      "419/419 [==============================] - 129s 307ms/step - loss: 0.6347 - acc: 0.7318 - val_loss: 0.4120 - val_acc: 0.8506\n",
      "Epoch 7/40\n",
      "419/419 [==============================] - 128s 305ms/step - loss: 0.6227 - acc: 0.7335 - val_loss: 0.3963 - val_acc: 0.8595\n",
      "Epoch 8/40\n",
      "419/419 [==============================] - 128s 306ms/step - loss: 0.5962 - acc: 0.7392 - val_loss: 0.3740 - val_acc: 0.8772\n",
      "Epoch 9/40\n",
      "419/419 [==============================] - 129s 308ms/step - loss: 0.5857 - acc: 0.7450 - val_loss: 0.4136 - val_acc: 0.8519\n",
      "Epoch 10/40\n",
      "419/419 [==============================] - 128s 307ms/step - loss: 0.5701 - acc: 0.7500 - val_loss: 0.3726 - val_acc: 0.8797\n",
      "Epoch 11/40\n",
      "419/419 [==============================] - 129s 307ms/step - loss: 0.5707 - acc: 0.7463 - val_loss: 0.3407 - val_acc: 0.8848\n",
      "Epoch 12/40\n",
      "419/419 [==============================] - 129s 307ms/step - loss: 0.5361 - acc: 0.7634 - val_loss: 0.3501 - val_acc: 0.8861\n",
      "Epoch 13/40\n",
      "419/419 [==============================] - 129s 308ms/step - loss: 0.5338 - acc: 0.7698 - val_loss: 0.3182 - val_acc: 0.8861\n",
      "Epoch 14/40\n",
      "419/419 [==============================] - 130s 309ms/step - loss: 0.5315 - acc: 0.7724 - val_loss: 0.3168 - val_acc: 0.8949\n",
      "Epoch 15/40\n",
      "419/419 [==============================] - 131s 312ms/step - loss: 0.5211 - acc: 0.7737 - val_loss: 0.3167 - val_acc: 0.9013\n",
      "Epoch 16/40\n",
      "419/419 [==============================] - 130s 310ms/step - loss: 0.5075 - acc: 0.7763 - val_loss: 0.3739 - val_acc: 0.8595\n",
      "Epoch 17/40\n",
      "419/419 [==============================] - 129s 308ms/step - loss: 0.5055 - acc: 0.7739 - val_loss: 0.3072 - val_acc: 0.8987\n",
      "Epoch 18/40\n",
      "419/419 [==============================] - 131s 312ms/step - loss: 0.5027 - acc: 0.7785 - val_loss: 0.3644 - val_acc: 0.8658\n",
      "Epoch 19/40\n",
      "419/419 [==============================] - 130s 310ms/step - loss: 0.4856 - acc: 0.7880 - val_loss: 0.2994 - val_acc: 0.8924\n",
      "Epoch 20/40\n",
      "419/419 [==============================] - 130s 309ms/step - loss: 0.4799 - acc: 0.7901 - val_loss: 0.3035 - val_acc: 0.9013\n",
      "Epoch 21/40\n",
      "419/419 [==============================] - 130s 311ms/step - loss: 0.4764 - acc: 0.7930 - val_loss: 0.3389 - val_acc: 0.8684\n",
      "Epoch 22/40\n",
      "419/419 [==============================] - 130s 310ms/step - loss: 0.4664 - acc: 0.7904 - val_loss: 0.3667 - val_acc: 0.8608\n",
      "Epoch 23/40\n",
      "419/419 [==============================] - 130s 310ms/step - loss: 0.4590 - acc: 0.8031 - val_loss: 0.3030 - val_acc: 0.8962\n",
      "Epoch 24/40\n",
      "419/419 [==============================] - 130s 311ms/step - loss: 0.4561 - acc: 0.8052 - val_loss: 0.2833 - val_acc: 0.9101\n",
      "Epoch 25/40\n",
      "419/419 [==============================] - 130s 311ms/step - loss: 0.4599 - acc: 0.7949 - val_loss: 0.3023 - val_acc: 0.8949\n",
      "Epoch 26/40\n",
      "419/419 [==============================] - 130s 311ms/step - loss: 0.4480 - acc: 0.8005 - val_loss: 0.2812 - val_acc: 0.9127\n",
      "Epoch 27/40\n",
      "419/419 [==============================] - 129s 309ms/step - loss: 0.4411 - acc: 0.8123 - val_loss: 0.2708 - val_acc: 0.9139\n",
      "Epoch 28/40\n",
      "419/419 [==============================] - 130s 310ms/step - loss: 0.4458 - acc: 0.8047 - val_loss: 0.2825 - val_acc: 0.9025\n",
      "Epoch 29/40\n",
      "419/419 [==============================] - 130s 310ms/step - loss: 0.4372 - acc: 0.8154 - val_loss: 0.2764 - val_acc: 0.9051\n",
      "Epoch 30/40\n",
      "419/419 [==============================] - 129s 309ms/step - loss: 0.4332 - acc: 0.8189 - val_loss: 0.3410 - val_acc: 0.8797\n",
      "Epoch 31/40\n",
      "419/419 [==============================] - 129s 308ms/step - loss: 0.4309 - acc: 0.8127 - val_loss: 0.3646 - val_acc: 0.8684\n",
      "Epoch 32/40\n",
      "419/419 [==============================] - 129s 309ms/step - loss: 0.4375 - acc: 0.8164 - val_loss: 0.2800 - val_acc: 0.9063\n",
      "Epoch 33/40\n",
      "419/419 [==============================] - 130s 310ms/step - loss: 0.4290 - acc: 0.8197 - val_loss: 0.2665 - val_acc: 0.9114\n",
      "Epoch 34/40\n",
      "419/419 [==============================] - 129s 309ms/step - loss: 0.4224 - acc: 0.8187 - val_loss: 0.2954 - val_acc: 0.8949\n",
      "Epoch 35/40\n",
      "419/419 [==============================] - 130s 310ms/step - loss: 0.4280 - acc: 0.8149 - val_loss: 0.2681 - val_acc: 0.9051\n",
      "Epoch 36/40\n",
      "419/419 [==============================] - 130s 309ms/step - loss: 0.4200 - acc: 0.8203 - val_loss: 0.2680 - val_acc: 0.9076\n",
      "Epoch 37/40\n",
      "419/419 [==============================] - 129s 308ms/step - loss: 0.4193 - acc: 0.8182 - val_loss: 0.2657 - val_acc: 0.9076\n",
      "Epoch 38/40\n",
      "419/419 [==============================] - 130s 311ms/step - loss: 0.4218 - acc: 0.8179 - val_loss: 0.2695 - val_acc: 0.9127\n",
      "Epoch 39/40\n",
      "419/419 [==============================] - 130s 310ms/step - loss: 0.4200 - acc: 0.8234 - val_loss: 0.3155 - val_acc: 0.8810\n",
      "Epoch 40/40\n",
      "419/419 [==============================] - 130s 310ms/step - loss: 0.4060 - acc: 0.8302 - val_loss: 0.2818 - val_acc: 0.8924\n",
      "396/396 [==============================] - 6s 14ms/step\n",
      "transfer_VGG16_585_l2_1.05E-04.hdf5\n",
      "reached an accuracy of 0.881 and loss of 0.304\n"
     ]
    }
   ],
   "source": [
    "model_save_name = 'transfer_'\n",
    "model_save_name += architecture.name\n",
    "log_output = os.path.join('logs', model_save_name)\n",
    "model_save_name += '.hdf5'\n",
    "os.makedirs(log_output, exist_ok=True)\n",
    "tb = TensorBoard(log_output)\n",
    "mc = ModelCheckpoint(os.path.join(\n",
    "     'Saved models transfer', model_save_name), save_best_only=True, save_weights_only=True)\n",
    "\n",
    "#mc = ModelCheckpoint(os.path.join(\n",
    "#    'Saved models_adience', model_save_name), save_best_only=True, save_weights_only=True)\n",
    "\n",
    "callbacks = [tb, mc]\n",
    "\n",
    "train = train_gen.flow_from_directory(dataset / 'train',\n",
    "                                      target_size=image_size,\n",
    "                                      batch_size=batch_size,\n",
    "                                      class_mode='categorical')\n",
    "total = train.n\n",
    "males = np.count_nonzero(train.classes)\n",
    "females = total - males\n",
    "# If males outnumber females, we get higher loss for females\n",
    "weights = {0: males/females, 1: 1}\n",
    "\n",
    "steps_per_epoch = int(np.ceil(total/batch_size))\n",
    "\n",
    "\n",
    "# Learning rate is low so that we don't ruin our parameters\n",
    "model.compile(optimizer=Nadam(lr=2e-6),  # default is 2e-3\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history_frozen = model.fit_generator(train,\n",
    "                                     epochs=15,\n",
    "                                     steps_per_epoch=steps_per_epoch,\n",
    "                                     validation_data=validation,\n",
    "                                     validation_steps=validation_steps,\n",
    "                                     class_weight=weights,\n",
    "                                     callbacks=callbacks)\n",
    "\n",
    "# Unfreezing all layers\n",
    "for layer in model.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Learning rate is low so that we don't ruin our parameters\n",
    "model.compile(optimizer=Nadam(lr=2e-6),  # default is 2e-3\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history_unfrozen = model.fit_generator(train,\n",
    "                    epochs=40,\n",
    "                   steps_per_epoch=steps_per_epoch,\n",
    "                   validation_data=validation,\n",
    "                   validation_steps=validation_steps,\n",
    "                   class_weight=weights,\n",
    "                   callbacks=callbacks)\n",
    "\n",
    "test_loss, test_acc = model.evaluate_generator(\n",
    "    test, steps=test.n, verbose=1)\n",
    "with open(os.path.join(log_output, 'histories'), 'wb') as f:\n",
    "    pickle.dump([history_frozen.history,\n",
    "                 history_unfrozen.history, test_loss, test_acc], f)\n",
    "print(f'{model_save_name}\\nreached an accuracy of {test_acc:.3f} and loss of {test_loss:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
