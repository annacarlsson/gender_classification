{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-31T09:40:18.831575Z",
     "start_time": "2019-05-31T09:40:18.819746Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Nadam\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard, LearningRateScheduler\n",
    "from models.models import *\n",
    "import tensorflow as tf\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-31T09:40:19.150458Z",
     "start_time": "2019-05-31T09:40:19.146614Z"
    }
   },
   "outputs": [],
   "source": [
    "# Number of searches performed\n",
    "hyperparameter_iterations = 10\n",
    "# epochs*(1frozen + 2unfrozen)\n",
    "epochs = 15\n",
    "# Batch size too small, bad approximation of the global loss.\n",
    "# Too large, gets stuck in minima.\n",
    "batch_size = 32\n",
    "\n",
    "# Default input size for many architectures\n",
    "image_size = (224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-31T09:40:19.893068Z",
     "start_time": "2019-05-31T09:40:19.667611Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2372 images belonging to 2 classes.\n",
      "Found 1186 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Dataset folder, expects three subdirectories:\n",
    "# validation, train, test\n",
    "dataset_name = 'UTKFace_Split'\n",
    "#dataset_name = 'Adience_Split'\n",
    "dataset = Path(dataset_name)\n",
    "\n",
    "val_test_gen = ImageDataGenerator(rescale=1./255)\n",
    "validation = val_test_gen.flow_from_directory(dataset / 'validation',\n",
    "                                              target_size = image_size,\n",
    "                                              batch_size = batch_size,\n",
    "                                              class_mode = 'categorical', shuffle=False)\n",
    "\n",
    "test = val_test_gen.flow_from_directory(dataset / 'test',\n",
    "                                        target_size = image_size,\n",
    "                                        batch_size = 1,\n",
    "                                        class_mode = 'categorical', shuffle=False)\n",
    "validation_steps = int(np.ceil(validation.n/batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-05-31T09:40:20.403Z"
    }
   },
   "outputs": [],
   "source": [
    "# Random search\n",
    "for _ in range(hyperparameter_iterations):\n",
    "    # Hyperparameters\n",
    "    filter_factor = np.random.randint(256,1024)\n",
    "    l2_factor = np.random.uniform(0,1e-3)\n",
    "    rotation_range = np.random.randint(0, 360)\n",
    "    shear_range = np.random.uniform(0, 360)\n",
    "    brightness = np.random.uniform(10)\n",
    "    brightness_range = (-brightness, brightness)\n",
    "    \n",
    "    # Hyperparameter MobileNet\n",
    "    alpha = np.random.choice([0.25, 0.50, 0.75,1.0])\n",
    "\n",
    "    # Architecture\n",
    "    architecture = MobileNetGenderFConnected(image_size, alpha, filter_factor, l2_factor)\n",
    "    model_save_name = f'{dataset_name}_{architecture.name}_rotation_{rotation_range}_shear_{shear_range:.2E}_brightness_{brightness:.2E}'\n",
    "    log_output = os.path.join(dataset_name, os.path.join('logs', model_save_name))\n",
    "    model_save_name += '{val_loss:.3f}.hdf5'\n",
    "    os.makedirs(log_output, exist_ok=True)\n",
    "    tb = TensorBoard(log_output)\n",
    "    mc = ModelCheckpoint(os.path.join('Saved models', model_save_name), save_best_only=True, save_weights_only=True)\n",
    "\n",
    "    callbacks = [tb, mc]\n",
    "    train_gen = ImageDataGenerator(rescale=1./255,\n",
    "                             horizontal_flip=True,\n",
    "                             shear_range=10,\n",
    "                             rotation_range=10)\n",
    "\n",
    "\n",
    "    train = train_gen.flow_from_directory(dataset /  'train',\n",
    "                                          target_size = image_size,\n",
    "                                          batch_size = batch_size,\n",
    "                                          class_mode = 'categorical')\n",
    "    total = train.n\n",
    "    males = np.count_nonzero(train.classes) \n",
    "    females = total - males\n",
    "    weights = {0: males/females, 1: 1} # If males outnumber females, we get higher loss for females\n",
    "    model = architecture.model\n",
    "    model.compile(optimizer=Nadam(),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    steps_per_epoch = int(np.ceil(total/batch_size))\n",
    "    wrapper = lambda x : model.fit_generator(train, \n",
    "                                        epochs=x, \n",
    "                                        steps_per_epoch=steps_per_epoch, \n",
    "                                        validation_data=validation, \n",
    "                                        validation_steps=validation_steps,\n",
    "                                        class_weight=weights,\n",
    "                                        callbacks=callbacks)\n",
    "\n",
    "    history_frozen = wrapper(epochs)\n",
    "\n",
    "    # Unfreezing all layers\n",
    "    for layer in enumerate(model.layers):\n",
    "        layer.trainable = True\n",
    "\n",
    "    # Learning rate is low so that we don't ruin our parameters\n",
    "    model.compile(optimizer=Nadam(lr=2e-6), # default is 2e-3\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    history_unfrozen = wrapper(epochs*2)\n",
    "    \n",
    "    test_loss, test_acc = model.evaluate_generator(test, steps=test.n, verbose=1)\n",
    "    with open(os.path.join(log_output, 'histories'), 'wb') as f:\n",
    "        pickle.dump([history_frozen.history, history_unfrozen.history, test_loss, test_acc], f) \n",
    "    print(f'{model_save_name}\\nreached an accuracy of {test_acc} and loss of {test_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
